############################ input configuration sections
[image]
csv_file = /data/fetal_scans_and_segmentations/SRR_and_Segmentations_preprocessed/image.csv
# filename_contains =
# filename_removefromid =
# filename_not_contains =
;spatial_window_size = (64, 64, 64)
spatial_window_size = (40, 40, 40)
interp_order = 3
pixdim = (1.0, 1.0, 1.0)
axcodes = (A, R, S)

[label]
csv_file = /data/fetal_scans_and_segmentations/SRR_and_Segmentations_preprocessed/label.csv
# filename_contains = _seg
# filename_not_contains =
# filename_removefromid =
;spatial_window_size = (64, 64, 64)
spatial_window_size = (40, 40, 40)
interp_order = 0
pixdim=(1.0, 1.0, 1.0)
axcodes=(A, R, S)

############################## system configuration sections
[SYSTEM]
cuda_devices = ""
num_threads = 2
num_gpus = 1
model_dir = ./models/fetal_parcellation/model_highres3dnet
dataset_split_file = /data/fetal_scans_and_segmentations/SRR_and_Segmentations_preprocessed/dataset_split.csv

[NETWORK]
name = highres3dnet
activation_function = relu
batch_size = 5
decay = 0.
reg_type = L2
keep_prob = 1

# volume level preprocessing
volume_padding_size = 0,0,0
# histogram normalisation
histogram_ref_file = ./standardisation_models.txt
norm_type = percentile
cutoff = (0.01, 0.99)
normalisation = False
whitening = True
normalise_foreground_only = False
foreground_type = otsu_plus
multimod_foreground_type = and

window_sampling = uniform

queue_length = 20


[TRAINING]
optimiser = adam
sample_per_volume = 1
# rotation_angle = (-10.0, 10.0)
# scaling_percentage = (-10.0, 10.0)
random_flipping_axes = 0
lr = 0.01
loss_type = Dice
starting_iter = 0
save_every_n = 50
tensorboard_every_n = 5
max_iter = 2000
max_checkpoints = 50

# Validation during training
validation_every_n = 20
# exclude_fraction_for_validation = 0.1
# exclude_fraction_for_inference = 0.2


[INFERENCE]
border = (10, 10, 10)
inference_iter = 1200
save_seg_dir = ./output/highres3dnet
output_interp_order = 0
;spatial_window_size = (64, 64, 64)
spatial_window_size = (40, 40, 40)
# this param is also used for evaluation: training, validation, or inference
dataset_to_infer = inference


[EVALUATION]
evaluations = dice,jaccard,specificity,sensitivity
evaluation_units = foreground
save_csv_dir = ./output/highres3dnet


############################ custom configuration sections
[SEGMENTATION]
image = image
label = label
output_prob = False
softmax = True
num_classes = 5
# map the labels set to consecutive integers starting from 0
label_normalisation = True
min_numb_labels = 2