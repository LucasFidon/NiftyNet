[brats_T1]
csv_file = /data/BraTS2019/brats_T1.csv
# csv_file = /home_directory/data/BraTS2019/brats_T1.csv
# path_to_search = /home/lucasf/data/BraTS2019/MICCAI_BraTS_2019_Data_Training_crop/
filename_contains = T1
filename_not_contains = T1c
# spatial_window_size = (128, 128, 128)
spatial_window_size = (40, 40, 40)
interp_order = 3
axcodes = (R, A, S)

[brats_T1c]
csv_file = /data/BraTS2019/brats_T1c.csv
# csv_file = /home_directory/data/BraTS2019/brats_T1c.csv
# path_to_search = /home/lucasf/data/BraTS2019/MICCAI_BraTS_2019_Data_Training_crop/
filename_contains = T1c
filename_not_contains = 
# spatial_window_size = (128, 128, 128)
spatial_window_size = (40, 40, 40)
interp_order = 3
axcodes = (R, A, S)

[brats_Flair]
csv_file = /data/BraTS2019/brats_Flair.csv
# csv_file = /home_directory/data/BraTS2019/brats_Flair.csv
# path_to_search = /data/BraTS2019/MICCAI_BraTS_2019_Data_Training_crop/
filename_contains = Flair
filename_not_contains = 
# spatial_window_size = (128, 128, 128)
spatial_window_size = (40, 40, 40)
interp_order = 3
axcodes = (R, A, S)

[brats_T2]
csv_file = /data/BraTS2019/brats_T2.csv
# csv_file = /home_directory/data/BraTS2019/brats_T2.csv
# path_to_search = /home/lucasf/data/BraTS2019/MICCAI_BraTS_2019_Data_Training_crop/
filename_contains = T2
filename_not_contains =
# spatial_window_size = (128, 128, 128)
spatial_window_size = (40, 40, 40)
interp_order = 3
axcodes = (R, A, S)

[label_b]
csv_file = /data/BraTS2019/brats_Label.csv
# csv_file = /home_directory/data/BraTS2019/brats_Label.csv
# path_to_search = /home/lucasf/data/BraTS2019/MICCAI_BraTS_2019_Data_Training_crop/
filename_contains = Label
filename_not_contains =
# spatial_window_size = (128, 128, 128)
spatial_window_size = (40, 40, 40)
interp_order = 0
axcodes = (R, A, S)

[SYSTEM]
cuda_devices = ""
num_threads = 8
num_gpus = 1
# choose the fold to use for validation
dataset_split_file = /data/BraTS2019/dataset_split_fold0.csv
# dataset_split_file = /home_directory/data/BraTS2019/dataset_split_fold0.csv
# csv with the subject proba of the training example (used only at training)
subject_proba_file = /data/BraTS2019/subject_proba_0.csv
# subject_proba_file = /home_directory/data/BraTS2019/subject_proba_0.csv
# model_dir = /home/lucasf/workspace/NiftyNet/models/BraTS19/u_mvae/
model_dir = /workspace/NiftyNet/models/BraTS19/u_mvae/

[NETWORK]
name = brats19.u_mvae_net.VAE
batch_size = 1
activation_function = relu
volume_padding_size = 10

whitening = True
normalisation = True
normalise_foreground_only=True
foreground_type = mean_plus
histogram_ref_file = /data/BraTS2019/histogram_ref_file.txt
# histogram_ref_file = /home_directory/data/BraTS2019/histogram_ref_file.txt
cutoff = (0.001, 0.999)
#window_sampling = uniform
# allow to sample the training subjects according to the proba given in subject_proba_file
window_sampling = subject_weighted
queue_length = 30
reg_type = L2
decay = 1e-5

[TRAINING]
# I changed the number pof sample per volume compared to Reuben exp
# that should lead to better or similar results...
# sample_per_volume = 32
sample_per_volume = 1
lr = 0.001
# note that the loss_type is ignored in variational_segmentation_application so far
# the loss is hard coded...
loss_type = Jaccard
starting_iter = 0
save_every_n = 5000
# max_iter = 10000
max_iter = 10000
max_checkpoints = 20
random_flipping_axes = 0,1,2
scaling_percentage =-10.0,10.0

exclude_fraction_for_validation = 0.
exclude_fraction_for_inference = 0.

[INFERENCE]
# Please use config_inf for inference
border = 10
inference_iter = 60000
save_seg_dir = ./output
output_interp_order = 0
spatial_window_size = (140, 140, 140)

[SEGMENTATION]
image = brats_T1, brats_T1c, brats_T2, brats_Flair
label = label_b
output_prob = False
num_classes = 4
